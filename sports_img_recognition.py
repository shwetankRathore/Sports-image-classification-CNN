{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# # ***PROJECT***\n# \n# # Sports image classification\n# **Shwetank Singh, Akash Kumar Sharma**\n# \n# **4th of August, 2021**\n# \n\n# %% [markdown]\n# # Abstract\n# In this Project we have used Convolutional Neural Network to recognise the sport from its image. We have considered 22 sports as \"badminton\", \"baseball\", \"basketball\", \"boxing\", \"chess\", \"cricket\", \"fencing\", \"football\", \"formula1\", \"gymnastics\", \"hockey\", \"ice_hockey\", \"kabaddi\", \"motogp\", \"shooting\", \"swimming\", \"table_tennis\", \"tennis\", \"volleyball\", \"weight_lifting\", \"wrestling\", \"wwe\". \n# ‘sports-image-dataset’, consists of 14141 observations/images with sports name as labels. Firstly, the data is divided into training set, validation set and test set with ratio 8:1:1. Then from the training set we found out the number of observations corresponding to each label. Next, we trained the training data on different models and based on accuracy from the Validation set , we have chosen the best model and found its test accuracy. Lastly, we test our model with some real examples. Here, we have only provided the best of all the models which we have tried.\n\n# %% [markdown]\n# # INTRODUCTION\n# \n# In the era of Artificial Intelligence many unbelievable things become possible. Using a machine we can find out the person in front of you are telling lie or truth, just seeing a image of person Facebook can detect its name and details, hearing our voice Google understands and shows us the relevant websites etc. \n# CNN in Deep Learning is one such tool to achieve perfection in image recognition. Significant additional impacts in image or object recognition were felt from 2011 to 2012. Although CNNs trained by backpropagation had been around for decades, and GPU implementations of NNs for years, including CNNs, fast implementations of CNNs with max-pooling on GPUs in the style of Ciresan and colleagues were needed to progress on computer vision. In 2011, this approach achieved for the first time superhuman performance in a visual pattern recognition contest. Also in 2011, it won the ICDAR Chinese handwriting contest, and in May 2012, it won the ISBI image segmentation contest. Until 2011, CNNs did not play a major role at computer vision conferences, but in June 2012, a paper by Ciresan et al. at the leading conference CVPR showed how max-pooling CNNs on GPU can dramatically improve many vision benchmark records. In November 2012, Ciresan et al.'s system also won the ICPR contest on analysis of large medical images for cancer detection.\n# \n# Here we also used CNN to recognise sports name by seeing the picture of the sport.\n\n# %% [markdown]\n# # OBJECTIVE\n# Objective of the project is to develop a sport recogniser based on 14.1K sample images.\n\n# %% [markdown]\n# # DATA INFORMATION\n# \n# This ‘sports-image-dataset’ data is collected from Kaggle. There are 14141 examples in the data and each example is rbg image. Data is divided into 80%, 10% and 10% respectively for train set, dev set and test set. Thus we get 11312 examples in the train set, 1414 examples the dev set and 1415 images in the test set.  The data consists of 22 folders with label name as sports name. Each folder consists of around 800-900 images. This dataset is collected from Google Images using Images Scrapper.\n# \n# It consists of 22 folders with label name as sports name. Each folder consists of around 800-900 images. This dataset is collected from Google Images using Images Scrapper.\n\n# %% [markdown]\n# # ANALYSIS\n# \n# In the whole analysis various models are used. These models vary by hyperparameters such as number of convnet layers, number of fully connected layers, number of filters, size of filter, activation functions, dropout and even training data size. As there are twentytwo categories , ‘softmax’ activation is in the final layer instead of ‘sigmoid’ (which is used for binary category). Keras is used in the analysis with Tensorflow at the backend.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T08:13:36.763924Z\",\"iopub.execute_input\":\"2021-08-04T08:13:36.764286Z\",\"iopub.status.idle\":\"2021-08-04T08:13:38.657916Z\",\"shell.execute_reply.started\":\"2021-08-04T08:13:36.764249Z\",\"shell.execute_reply\":\"2021-08-04T08:13:38.657053Z\"},\"jupyter\":{\"outputs_hidden\":true}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [markdown]\n# # Necessary modules to Import\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:16:39.388893Z\",\"iopub.execute_input\":\"2021-08-04T06:16:39.389523Z\",\"iopub.status.idle\":\"2021-08-04T06:16:45.380237Z\",\"shell.execute_reply.started\":\"2021-08-04T06:16:39.389453Z\",\"shell.execute_reply\":\"2021-08-04T06:16:45.379258Z\"}}\n! pip install imutils\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:16:45.382085Z\",\"iopub.execute_input\":\"2021-08-04T06:16:45.382463Z\",\"iopub.status.idle\":\"2021-08-04T06:16:47.352663Z\",\"shell.execute_reply.started\":\"2021-08-04T06:16:45.382422Z\",\"shell.execute_reply\":\"2021-08-04T06:16:47.351792Z\"}}\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\n\n# import the necessary packages\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport random\nimport pickle\nimport cv2\nimport os\n%matplotlib inline\n\n# %% [markdown]\n# # Visiting the data\n# Let's check the data.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:16:47.353911Z\",\"iopub.execute_input\":\"2021-08-04T06:16:47.354341Z\",\"iopub.status.idle\":\"2021-08-04T06:17:43.553911Z\",\"shell.execute_reply.started\":\"2021-08-04T06:16:47.354303Z\",\"shell.execute_reply\":\"2021-08-04T06:17:43.55299Z\"}}\n# initialize the data and labels\nprint(\"[INFO] loading images...\")\ndata = []\nlabels = []\n#Enter the path of your image data folder\nimage_data_folder_path = \"../input/sports-image-dataset/data\"\n\n# grab the image paths and randomly shuffle them\nimagePaths = sorted(list(paths.list_images(image_data_folder_path)))\n\ntotal_number_of_images = len(imagePaths)\nprint(\"\\n\")\nprint(\"Total number of images----->\",total_number_of_images)\nrandom.shuffle(imagePaths)\n\n# loop over the input images\nfor imagePath in imagePaths:\n    # load the image, resize it to 84x84 pixels (the required input\n    # spatial dimensions of SmallVGGNet), and store the image in the\n    # data list\n    image = cv2.imread(imagePath)\n    image = cv2.resize(image, (84,84))\n    data.append(image)\n\n    # extract the class label from the image path and update the\n    # labels list\n    label = imagePath.split(os.path.sep)[-2]\n    labels.append(label)\nprint (\"data\",data[0].shape)\n\n# scale the raw pixel intensities to the range [0, 1]\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)\nprint(labels)\nprint(labels.shape)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:43.555334Z\",\"iopub.execute_input\":\"2021-08-04T06:17:43.555983Z\",\"iopub.status.idle\":\"2021-08-04T06:17:44.427271Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:43.555939Z\",\"shell.execute_reply\":\"2021-08-04T06:17:44.42629Z\"}}\n# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n(trainX, val_testX, trainY, val_testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\nprint (\"trainX.shape------>>\",trainX.shape)\n(testX, valX, testY, valY) = train_test_split(val_testX, val_testY, test_size=0.5, random_state=42)\n\n# convert the labels from integers to vectors\nlb = LabelBinarizer()\ntrainY = lb.fit_transform(trainY)\ntestY = lb.transform(testY)\nvalY = lb.transform(valY)\n\nheight = 84\nwidth = 84\ndepth =3\n\ninputShape = (height, width, depth)\n\nclasses = len(lb.classes_)\nprint(\"Number of classes:\",classes)\nprint(\"Number of training images:\", len(trainX))\nprint(\"Number of validation images:\", len(valY))\nprint(\"Number of test images:\", len(testX))\n\n# %% [markdown]\n# Dividing data into training set, validation(developement) set and testing set\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:44.428762Z\",\"iopub.execute_input\":\"2021-08-04T06:17:44.429121Z\",\"iopub.status.idle\":\"2021-08-04T06:17:44.434148Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:44.429084Z\",\"shell.execute_reply\":\"2021-08-04T06:17:44.43331Z\"}}\nclasses_name =  [\"badminton\", \"baseball\", \"basketball\", \"boxing\", \n                \"chess\", \"cricket\", \"fencing\", \"football\", \"formula1\", \n                \"gymnastics\", \"hockey\", \"ice_hockey\", \"kabaddi\", \"motogp\", \n                \"shooting\", \"swimming\", \"table_tennis\", \"tennis\", \"volleyball\", \n                \"weight_lifting\", \"wrestling\", \"wwe\"]\n\n# %% [markdown]\n# # Plotting some images from data randomly\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:44.435521Z\",\"iopub.execute_input\":\"2021-08-04T06:17:44.436153Z\",\"iopub.status.idle\":\"2021-08-04T06:17:45.872436Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:44.436114Z\",\"shell.execute_reply\":\"2021-08-04T06:17:45.87112Z\"}}\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(trainX[i], cmap=plt.cm.binary)\n    plt.xlabel(classes_name[np.argmax(trainY[i])])\nplt.show()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:45.876168Z\",\"iopub.execute_input\":\"2021-08-04T06:17:45.876811Z\",\"iopub.status.idle\":\"2021-08-04T06:17:45.881132Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:45.876771Z\",\"shell.execute_reply\":\"2021-08-04T06:17:45.880389Z\"}}\n# initialize number of epochs to train for, and batch size\nEPOCHS = 50\nBS = 32\n\n# %% [markdown]\n# number of epochs and batch size\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:45.883299Z\",\"iopub.execute_input\":\"2021-08-04T06:17:45.883882Z\",\"iopub.status.idle\":\"2021-08-04T06:17:45.90165Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:45.883846Z\",\"shell.execute_reply\":\"2021-08-04T06:17:45.900671Z\"}}\nrandom_state = 99\n\n# %% [markdown]\n# # **MODEL1**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:45.902905Z\",\"iopub.execute_input\":\"2021-08-04T06:17:45.903273Z\",\"iopub.status.idle\":\"2021-08-04T06:17:46.97681Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:45.903239Z\",\"shell.execute_reply\":\"2021-08-04T06:17:46.975877Z\"}}\nchanDim=3\nmodel1 = Sequential()\n# CONV => RELU => POOL layer set\nmodel1.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization(axis=chanDim))\nmodel1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.25))\n\n# (CONV => RELU) * 2 => POOL layer set\nmodel1.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization(axis=chanDim))\nmodel1.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization(axis=chanDim))\nmodel1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.25))\n\n# (CONV => RELU) * 3 => POOL layer set\nmodel1.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization(axis=chanDim))\nmodel1.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization(axis=chanDim))\nmodel1.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization(axis=chanDim))\nmodel1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.25))\n\n# first (and only) set of FC => RELU layers\nmodel1.add(Flatten())\nmodel1.add(Dense(512))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.5))\nmodel1.add(Dense(128))\nmodel1.add(Activation(\"relu\"))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.3))\n\n\n# softmax classifier\nmodel1.add(Dense(classes))\nmodel1.add(Activation(\"softmax\"))\n\n\nmodel1.summary()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:46.978373Z\",\"iopub.execute_input\":\"2021-08-04T06:17:46.978721Z\",\"iopub.status.idle\":\"2021-08-04T06:17:46.995879Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:46.978684Z\",\"shell.execute_reply\":\"2021-08-04T06:17:46.994633Z\"}}\n# initialize the model and optimizer\nmodel1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:17:46.997709Z\",\"iopub.execute_input\":\"2021-08-04T06:17:46.998172Z\",\"iopub.status.idle\":\"2021-08-04T06:22:40.293488Z\",\"shell.execute_reply.started\":\"2021-08-04T06:17:46.998117Z\",\"shell.execute_reply\":\"2021-08-04T06:22:40.292566Z\"}}\n# train the network\nH1 = model1.fit(trainX, trainY, batch_size=BS,\n    validation_data=(valX, valY), steps_per_epoch=len(trainX) // BS,\n    epochs=EPOCHS)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:22:40.295233Z\",\"iopub.execute_input\":\"2021-08-04T06:22:40.295601Z\",\"iopub.status.idle\":\"2021-08-04T06:22:40.792335Z\",\"shell.execute_reply.started\":\"2021-08-04T06:22:40.295561Z\",\"shell.execute_reply\":\"2021-08-04T06:22:40.791427Z\"}}\npreds1=model1.evaluate(testX, testY, batch_size=32)\nprint('loss = '+str(preds1[0]))\nprint('test accuracy = '+str(preds1[1]))\n\n# %% [markdown]\n# We got 63.02% test accuracy using 'Adam' optimizer.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:22:40.793532Z\",\"iopub.execute_input\":\"2021-08-04T06:22:40.793865Z\",\"iopub.status.idle\":\"2021-08-04T06:22:41.31009Z\",\"shell.execute_reply.started\":\"2021-08-04T06:22:40.793826Z\",\"shell.execute_reply\":\"2021-08-04T06:22:41.309258Z\"}}\n# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions1 = model1.predict(valX, batch_size=32)\nprint(classification_report(valY.argmax(axis=1),\n    predictions1.argmax(axis=1), target_names=lb.classes_))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:22:41.311591Z\",\"iopub.execute_input\":\"2021-08-04T06:22:41.311976Z\",\"iopub.status.idle\":\"2021-08-04T06:22:41.606083Z\",\"shell.execute_reply.started\":\"2021-08-04T06:22:41.311937Z\",\"shell.execute_reply\":\"2021-08-04T06:22:41.605101Z\"}}\n# plot the training loss and accuracy\nN = np.arange(0, EPOCHS)\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(8,8))\nplt.plot(N, H1.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, H1.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, H1.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(N, H1.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.savefig(\"smallvggnet_plot.png\")\nplt.show()\n\n# %% [markdown]\n# Clearly the model is overfit. Now we want to do some regualrization, such as try some different optimizer.\n\n# %% [markdown]\n# # **MODEL 2**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:22:41.607613Z\",\"iopub.execute_input\":\"2021-08-04T06:22:41.607963Z\",\"iopub.status.idle\":\"2021-08-04T06:22:41.838832Z\",\"shell.execute_reply.started\":\"2021-08-04T06:22:41.607927Z\",\"shell.execute_reply\":\"2021-08-04T06:22:41.838028Z\"}}\nchanDim=3\nmodel2 = Sequential()\n# CONV => RELU => POOL layer set\nmodel2.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# (CONV => RELU) * 2 => POOL layer set\nmodel2.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# (CONV => RELU) * 3 => POOL layer set\nmodel2.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# first (and only) set of FC => RELU layers\nmodel2.add(Flatten())\nmodel2.add(Dense(512))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization())\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(128))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization())\nmodel2.add(Dropout(0.3))\n\n\n# softmax classifier\nmodel2.add(Dense(classes))\nmodel2.add(Activation(\"softmax\"))\n\n\nmodel2.summary()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:22:41.843506Z\",\"iopub.execute_input\":\"2021-08-04T06:22:41.843758Z\",\"iopub.status.idle\":\"2021-08-04T06:22:41.858079Z\",\"shell.execute_reply.started\":\"2021-08-04T06:22:41.843731Z\",\"shell.execute_reply\":\"2021-08-04T06:22:41.856989Z\"}}\n# initialize the model and optimizermodel2 = model()\nmodel2.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:22:41.859541Z\",\"iopub.execute_input\":\"2021-08-04T06:22:41.859946Z\",\"iopub.status.idle\":\"2021-08-04T06:28:04.131814Z\",\"shell.execute_reply.started\":\"2021-08-04T06:22:41.859905Z\",\"shell.execute_reply\":\"2021-08-04T06:28:04.130975Z\"}}\nH2 = model2.fit(trainX, trainY, batch_size=BS,\n    validation_data=(valX, valY), steps_per_epoch=len(trainX) // BS,\n    epochs=EPOCHS)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:28:04.13345Z\",\"iopub.execute_input\":\"2021-08-04T06:28:04.133809Z\",\"iopub.status.idle\":\"2021-08-04T06:28:04.603604Z\",\"shell.execute_reply.started\":\"2021-08-04T06:28:04.133773Z\",\"shell.execute_reply\":\"2021-08-04T06:28:04.60246Z\"}}\npreds2=model2.evaluate(testX, testY, batch_size=32)\nprint('loss = '+str(preds2[0]))\nprint('test accuracy = '+str(preds2[1]))\n\n# %% [markdown]\n# We got 62.02% test accuracy using 'RMSprop' optimizer.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:28:04.605136Z\",\"iopub.execute_input\":\"2021-08-04T06:28:04.60552Z\",\"iopub.status.idle\":\"2021-08-04T06:28:05.085711Z\",\"shell.execute_reply.started\":\"2021-08-04T06:28:04.605482Z\",\"shell.execute_reply\":\"2021-08-04T06:28:05.084833Z\"}}\n# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions2 = model2.predict(valX, batch_size=32)\nprint(classification_report(valY.argmax(axis=1),\n    predictions2.argmax(axis=1), target_names=lb.classes_))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:28:05.086962Z\",\"iopub.execute_input\":\"2021-08-04T06:28:05.087465Z\",\"iopub.status.idle\":\"2021-08-04T06:28:05.363598Z\",\"shell.execute_reply.started\":\"2021-08-04T06:28:05.087426Z\",\"shell.execute_reply\":\"2021-08-04T06:28:05.362586Z\"}}\n# plot the training loss and accuracy for model 2\nN = np.arange(0, EPOCHS)\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(8,8))\nplt.plot(N, H2.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, H2.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, H2.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(N, H2.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.savefig(\"smallvggnet_plot.png\")\nplt.show()\n\n# %% [markdown]\n# Still we can observe high overfitting. So I want to try another optimizer.\n\n# %% [markdown]\n# # **MODEL 3**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:28:05.365107Z\",\"iopub.execute_input\":\"2021-08-04T06:28:05.365483Z\",\"iopub.status.idle\":\"2021-08-04T06:28:05.592878Z\",\"shell.execute_reply.started\":\"2021-08-04T06:28:05.365444Z\",\"shell.execute_reply\":\"2021-08-04T06:28:05.592084Z\"}}\nchanDim=3\nmodel3 = Sequential()\n# CONV => RELU => POOL layer set\nmodel3.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization(axis=chanDim))\nmodel3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel3.add(Dropout(0.25))\n\n# (CONV => RELU) * 2 => POOL layer set\nmodel3.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization(axis=chanDim))\nmodel3.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization(axis=chanDim))\nmodel3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel3.add(Dropout(0.25))\n\n# (CONV => RELU) * 3 => POOL layer set\nmodel3.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization(axis=chanDim))\nmodel3.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization(axis=chanDim))\nmodel3.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization(axis=chanDim))\nmodel3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel3.add(Dropout(0.25))\n\n# first (and only) set of FC => RELU layers\nmodel3.add(Flatten())\nmodel3.add(Dense(512))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization())\nmodel3.add(Dropout(0.5))\nmodel3.add(Dense(128))\nmodel3.add(Activation(\"relu\"))\nmodel3.add(BatchNormalization())\nmodel3.add(Dropout(0.3))\n\n# softmax classifier\nmodel3.add(Dense(classes))\nmodel3.add(Activation(\"softmax\"))\n\n\nmodel3.summary()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:28:05.597549Z\",\"iopub.execute_input\":\"2021-08-04T06:28:05.597801Z\",\"iopub.status.idle\":\"2021-08-04T06:28:05.611182Z\",\"shell.execute_reply.started\":\"2021-08-04T06:28:05.597775Z\",\"shell.execute_reply\":\"2021-08-04T06:28:05.610001Z\"}}\n# initialize the model and optimizermodel2 = model()\nmodel3.compile(loss=\"categorical_crossentropy\", optimizer=\"adamax\", metrics=[\"accuracy\"])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:28:05.612685Z\",\"iopub.execute_input\":\"2021-08-04T06:28:05.613247Z\",\"iopub.status.idle\":\"2021-08-04T06:33:03.998207Z\",\"shell.execute_reply.started\":\"2021-08-04T06:28:05.613192Z\",\"shell.execute_reply\":\"2021-08-04T06:33:03.99731Z\"}}\nH3 = model3.fit(trainX, trainY, batch_size=BS,\n    validation_data=(valX, valY), steps_per_epoch=len(trainX) // BS,\n    epochs=EPOCHS)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:33:03.999795Z\",\"iopub.execute_input\":\"2021-08-04T06:33:04.000324Z\",\"iopub.status.idle\":\"2021-08-04T06:33:04.462751Z\",\"shell.execute_reply.started\":\"2021-08-04T06:33:04.000286Z\",\"shell.execute_reply\":\"2021-08-04T06:33:04.461769Z\"}}\npreds3=model3.evaluate(testX, testY, batch_size=32)\nprint('loss = '+str(preds3[0]))\nprint('test accuracy = '+str(preds3[1]))\n\n# %% [markdown]\n# We got 64.28% test accuracy using 'Adamax' optimizer.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:33:04.467718Z\",\"iopub.execute_input\":\"2021-08-04T06:33:04.468076Z\",\"iopub.status.idle\":\"2021-08-04T06:33:04.955498Z\",\"shell.execute_reply.started\":\"2021-08-04T06:33:04.468035Z\",\"shell.execute_reply\":\"2021-08-04T06:33:04.954589Z\"}}\n# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions3 = model3.predict(valX, batch_size=32)\nprint(classification_report(valY.argmax(axis=1),\n    predictions3.argmax(axis=1), target_names=lb.classes_))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:33:04.95736Z\",\"iopub.execute_input\":\"2021-08-04T06:33:04.957823Z\",\"iopub.status.idle\":\"2021-08-04T06:33:05.25593Z\",\"shell.execute_reply.started\":\"2021-08-04T06:33:04.957786Z\",\"shell.execute_reply\":\"2021-08-04T06:33:05.254939Z\"}}\n# plot the training loss and accuracy for model 2\nN = np.arange(0, EPOCHS)\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(8,8))\nplt.plot(N, H3.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, H3.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, H3.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(N, H3.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.savefig(\"smallvggnet_plot.png\")\nplt.show()\n\n# %% [markdown]\n# Still we are facing the problem of overfitting. Now we will try some other regularization like adding or increasing Dropouts.\n\n# %% [markdown]\n# # **MODEL 4**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:33:05.257435Z\",\"iopub.execute_input\":\"2021-08-04T06:33:05.257791Z\",\"iopub.status.idle\":\"2021-08-04T06:33:05.519335Z\",\"shell.execute_reply.started\":\"2021-08-04T06:33:05.257754Z\",\"shell.execute_reply\":\"2021-08-04T06:33:05.518377Z\"}}\nchanDim=3\nmodel4 = Sequential()\n# CONV => RELU => POOL layer set\nmodel4.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization(axis=chanDim))\nmodel4.add(MaxPooling2D(pool_size=(2, 2)))\nmodel4.add(Dropout(0.5))\n\n# (CONV => RELU) * 2 => POOL layer set\nmodel4.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization(axis=chanDim))\nmodel4.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization(axis=chanDim))\nmodel4.add(MaxPooling2D(pool_size=(2, 2)))\nmodel4.add(Dropout(0.5))\n\n# (CONV => RELU) * 3 => POOL layer set\nmodel4.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization(axis=chanDim))\nmodel4.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization(axis=chanDim))\nmodel4.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization(axis=chanDim))\nmodel4.add(MaxPooling2D(pool_size=(2, 2)))\nmodel4.add(Dropout(0.5))\n\n# first (and only) set of FC => RELU layers\nmodel4.add(Flatten())\nmodel4.add(Dense(512))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization())\nmodel4.add(Dropout(0.5))\nmodel4.add(Dense(128))\nmodel4.add(Activation(\"relu\"))\nmodel4.add(BatchNormalization())\nmodel4.add(Dropout(0.3))\n\n# softmax classifier\nmodel4.add(Dense(classes))\nmodel4.add(Activation(\"softmax\"))\n\n\nmodel4.summary()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:33:05.520893Z\",\"iopub.execute_input\":\"2021-08-04T06:33:05.521298Z\",\"iopub.status.idle\":\"2021-08-04T06:33:05.536906Z\",\"shell.execute_reply.started\":\"2021-08-04T06:33:05.521256Z\",\"shell.execute_reply\":\"2021-08-04T06:33:05.535722Z\"}}\n# initialize the model and optimizermodel2 = model()\nmodel4.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:33:05.538993Z\",\"iopub.execute_input\":\"2021-08-04T06:33:05.539491Z\",\"iopub.status.idle\":\"2021-08-04T06:38:30.953589Z\",\"shell.execute_reply.started\":\"2021-08-04T06:33:05.539448Z\",\"shell.execute_reply\":\"2021-08-04T06:38:30.952757Z\"}}\nH4 = model4.fit(trainX, trainY, batch_size=BS,\n    validation_data=(valX, valY), steps_per_epoch=len(trainX) // BS,\n    epochs=EPOCHS)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:38:30.955079Z\",\"iopub.execute_input\":\"2021-08-04T06:38:30.955465Z\",\"iopub.status.idle\":\"2021-08-04T06:38:31.417524Z\",\"shell.execute_reply.started\":\"2021-08-04T06:38:30.955427Z\",\"shell.execute_reply\":\"2021-08-04T06:38:31.416549Z\"}}\npreds4=model4.evaluate(testX, testY, batch_size=32)\nprint('loss = '+str(preds4[0]))\nprint('test accuracy = '+str(preds4[1]))\n\n# %% [markdown]\n# We got 63.43% test accuracy when we increased the dropouts.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:38:31.419129Z\",\"iopub.execute_input\":\"2021-08-04T06:38:31.419517Z\",\"iopub.status.idle\":\"2021-08-04T06:38:31.89697Z\",\"shell.execute_reply.started\":\"2021-08-04T06:38:31.419479Z\",\"shell.execute_reply\":\"2021-08-04T06:38:31.89604Z\"}}\n# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions4 = model4.predict(valX, batch_size=32)\nprint(classification_report(valY.argmax(axis=1),\n    predictions4.argmax(axis=1), target_names=lb.classes_))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:38:31.898593Z\",\"iopub.execute_input\":\"2021-08-04T06:38:31.899289Z\",\"iopub.status.idle\":\"2021-08-04T06:38:32.162099Z\",\"shell.execute_reply.started\":\"2021-08-04T06:38:31.899249Z\",\"shell.execute_reply\":\"2021-08-04T06:38:32.161121Z\"}}\n# plot the training loss and accuracy for model 2\nN = np.arange(0, EPOCHS)\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(8,8))\nplt.plot(N, H4.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, H4.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, H4.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(N, H4.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.savefig(\"smallvggnet_plot.png\")\nplt.show()\n\n# %% [markdown]\n# We can observe overfitting is reduced but we are loosing accuracy at the same time.\n# To tackle both these problems together we will increase our training data. We will do so by using Data Augmentation.\n\n# %% [markdown]\n# # **MODEL 5**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:38:32.163592Z\",\"iopub.execute_input\":\"2021-08-04T06:38:32.163954Z\",\"iopub.status.idle\":\"2021-08-04T06:38:32.169187Z\",\"shell.execute_reply.started\":\"2021-08-04T06:38:32.163915Z\",\"shell.execute_reply\":\"2021-08-04T06:38:32.168294Z\"}}\n# Data Augmentation\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n    horizontal_flip=True, fill_mode=\"nearest\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:38:32.170445Z\",\"iopub.execute_input\":\"2021-08-04T06:38:32.17078Z\",\"iopub.status.idle\":\"2021-08-04T06:38:32.429454Z\",\"shell.execute_reply.started\":\"2021-08-04T06:38:32.170745Z\",\"shell.execute_reply\":\"2021-08-04T06:38:32.428212Z\"}}\nchanDim=3\nmodel5 = Sequential()\n# CONV => RELU => POOL layer set\nmodel5.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=inputShape))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization(axis=chanDim))\nmodel5.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization(axis=chanDim))\nmodel5.add(MaxPooling2D(pool_size=(2, 2)))\nmodel5.add(Dropout(0.25))\n\n# (CONV => RELU) * 2 => POOL layer set\nmodel5.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization(axis=chanDim))\nmodel5.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization(axis=chanDim))\nmodel5.add(MaxPooling2D(pool_size=(2, 2)))\nmodel5.add(Dropout(0.3))\n\n# (CONV => RELU) * 3 => POOL layer set\nmodel5.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization(axis=chanDim))\nmodel5.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization(axis=chanDim))\nmodel5.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization(axis=chanDim))\nmodel5.add(MaxPooling2D(pool_size=(2, 2)))\nmodel5.add(Dropout(0.5))\n\n# first (and only) set of FC => RELU layers\nmodel5.add(Flatten())\nmodel5.add(Dense(512))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization())\nmodel5.add(Dropout(0.5))\nmodel5.add(Dense(128))\nmodel5.add(Activation(\"relu\"))\nmodel5.add(BatchNormalization())\nmodel5.add(Dropout(0.3))\n\n# softmax classifier\nmodel5.add(Dense(classes))\nmodel5.add(Activation(\"softmax\"))\n\n\nmodel5.summary()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:38:32.430826Z\",\"iopub.execute_input\":\"2021-08-04T06:38:32.431163Z\",\"iopub.status.idle\":\"2021-08-04T06:38:32.444603Z\",\"shell.execute_reply.started\":\"2021-08-04T06:38:32.431127Z\",\"shell.execute_reply\":\"2021-08-04T06:38:32.443487Z\"}}\n# initialize the model and optimizermodel2 = model()\nmodel5.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T06:38:32.446051Z\",\"iopub.execute_input\":\"2021-08-04T06:38:32.446611Z\",\"iopub.status.idle\":\"2021-08-04T07:24:09.280024Z\",\"shell.execute_reply.started\":\"2021-08-04T06:38:32.446573Z\",\"shell.execute_reply\":\"2021-08-04T07:24:09.27916Z\"}}\nH5 = model5.fit(aug.flow(trainX, trainY, batch_size=BS),\n    validation_data=(valX, valY), steps_per_epoch=len(trainX) // BS,\n    epochs=100)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:09.284986Z\",\"iopub.execute_input\":\"2021-08-04T07:24:09.285264Z\",\"iopub.status.idle\":\"2021-08-04T07:24:10.147059Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:09.285236Z\",\"shell.execute_reply\":\"2021-08-04T07:24:10.146253Z\"}}\npreds5 = model5.evaluate(testX, testY, batch_size=32)\nprint('loss = '+str(preds5[0]))\nprint('test accuracy = '+str(preds5[1]))\n\n# %% [markdown]\n# We got 72.98% test accuracy which is higher than all the model used.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:10.148163Z\",\"iopub.execute_input\":\"2021-08-04T07:24:10.148497Z\",\"iopub.status.idle\":\"2021-08-04T07:24:10.978426Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:10.148465Z\",\"shell.execute_reply\":\"2021-08-04T07:24:10.977489Z\"}}\n# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions5 = model5.predict(valX, batch_size=32)\nprint(classification_report(valY.argmax(axis=1),\n    predictions5.argmax(axis=1), target_names=lb.classes_))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:10.979881Z\",\"iopub.execute_input\":\"2021-08-04T07:24:10.980264Z\",\"iopub.status.idle\":\"2021-08-04T07:24:11.247572Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:10.980212Z\",\"shell.execute_reply\":\"2021-08-04T07:24:11.246604Z\"}}\n# plot the training loss and accuracy for model 2\nN = np.arange(0, 100)\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(8,8))\nplt.plot(N, H5.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, H5.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, H5.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(N, H5.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.savefig(\"smallvggnet_plot.png\")\nplt.show()\n\n# %% [markdown]\n# We can see that overfitting is reduced by a large extent. So, Model 5 is the best, and this is our final model. Now we test some real life pictures with this model to check its accuracy.\n\n# %% [markdown]\n# # Prediction for some internet images\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:11.249043Z\",\"iopub.execute_input\":\"2021-08-04T07:24:11.249417Z\",\"iopub.status.idle\":\"2021-08-04T07:24:11.754288Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:11.249381Z\",\"shell.execute_reply\":\"2021-08-04T07:24:11.753336Z\"}}\nfrom skimage import io\nimport PIL\nfrom keras.preprocessing import image\nshow_img=image.load_img('../input/images/image1.jpg', grayscale=False, target_size=(200, 200,3))\nplt.imshow(show_img);\n\nimagePath=\"../input/images/image1.jpg\"\nimage = cv2.imread(imagePath)\nimage = cv2.resize(image, (84,84))\nplt.imshow(image)\n\nx = np.expand_dims(image, axis = 0)\nx = np.array(x, dtype=\"float\") / 255.0\n\n\nprediction=model5.predict(x)\nindex=np.argmax(prediction[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(classes_name[index], 100 * np.max(prediction[0]))\n)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:11.755709Z\",\"iopub.execute_input\":\"2021-08-04T07:24:11.756077Z\",\"iopub.status.idle\":\"2021-08-04T07:24:12.011211Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:11.756036Z\",\"shell.execute_reply\":\"2021-08-04T07:24:12.010238Z\"}}\nfrom skimage import io\nimport PIL\nfrom keras.preprocessing import image\nshow_img=image.load_img('../input/images/iamge2.jpg', grayscale=False, target_size=(200, 200,3))\nplt.imshow(show_img);\n\nimagePath=\"../input/images/iamge2.jpg\"\nimage = cv2.imread(imagePath)\nimage = cv2.resize(image, (84,84))\nplt.imshow(image)\n\nx = np.expand_dims(image, axis = 0)\nx = np.array(x, dtype=\"float\") / 255.0\n\n\nprediction=model5.predict(x)\nindex=np.argmax(prediction[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(classes_name[index], 100 * np.max(prediction[0]))\n)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:12.012939Z\",\"iopub.execute_input\":\"2021-08-04T07:24:12.01333Z\",\"iopub.status.idle\":\"2021-08-04T07:24:12.474077Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:12.01329Z\",\"shell.execute_reply\":\"2021-08-04T07:24:12.473089Z\"}}\nfrom skimage import io\nimport PIL\nfrom keras.preprocessing import image\nshow_img=image.load_img('../input/images/image3.jpeg', grayscale=False, target_size=(200, 200,3))\nplt.imshow(show_img);\n\nimagePath=\"../input/images/image3.jpeg\"\nimage = cv2.imread(imagePath)\nimage = cv2.resize(image, (84,84))\nplt.imshow(image)\n\nx = np.expand_dims(image, axis = 0)\nx = np.array(x, dtype=\"float\") / 255.0\n\n\nprediction=model5.predict(x)\nindex=np.argmax(prediction[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(classes_name[index], 100 * np.max(prediction[0]))\n)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:12.475751Z\",\"iopub.execute_input\":\"2021-08-04T07:24:12.476077Z\",\"iopub.status.idle\":\"2021-08-04T07:24:12.73556Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:12.476044Z\",\"shell.execute_reply\":\"2021-08-04T07:24:12.734501Z\"}}\nfrom skimage import io\nimport PIL\nfrom keras.preprocessing import image\nshow_img=image.load_img('../input/images/image4.jpg', grayscale=False, target_size=(200, 200,3))\nplt.imshow(show_img);\n\nimagePath=\"../input/images/image4.jpg\"\nimage = cv2.imread(imagePath)\nimage = cv2.resize(image, (84,84))\nplt.imshow(image)\n\nx = np.expand_dims(image, axis = 0)\nx = np.array(x, dtype=\"float\") / 255.0\n\n\nprediction=model5.predict(x)\nindex=np.argmax(prediction[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(classes_name[index], 100 * np.max(prediction[0]))\n)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:12.73718Z\",\"iopub.execute_input\":\"2021-08-04T07:24:12.737546Z\",\"iopub.status.idle\":\"2021-08-04T07:24:12.999418Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:12.737509Z\",\"shell.execute_reply\":\"2021-08-04T07:24:12.998432Z\"}}\nfrom skimage import io\nimport PIL\nfrom keras.preprocessing import image\nshow_img=image.load_img('../input/images/image5.jpg', grayscale=False, target_size=(200, 200,3))\nplt.imshow(show_img);\n\nimagePath=\"../input/images/image5.jpg\"\nimage = cv2.imread(imagePath)\nimage = cv2.resize(image, (84,84))\nplt.imshow(image)\n\nx = np.expand_dims(image, axis = 0)\nx = np.array(x, dtype=\"float\") / 255.0\n\n\nprediction=model5.predict(x)\nindex=np.argmax(prediction[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(classes_name[index], 100 * np.max(prediction[0]))\n)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-04T07:24:13.001106Z\",\"iopub.execute_input\":\"2021-08-04T07:24:13.001482Z\",\"iopub.status.idle\":\"2021-08-04T07:24:13.264457Z\",\"shell.execute_reply.started\":\"2021-08-04T07:24:13.001444Z\",\"shell.execute_reply\":\"2021-08-04T07:24:13.263464Z\"}}\nfrom skimage import io\nimport PIL\nfrom keras.preprocessing import image\nshow_img=image.load_img('../input/images/image6.jpg', grayscale=False, target_size=(200, 200,3))\nplt.imshow(show_img);\n\nimagePath=\"../input/images/image6.jpg\"\nimage = cv2.imread(imagePath)\nimage = cv2.resize(image, (84,84))\nplt.imshow(image)\n\nx = np.expand_dims(image, axis = 0)\nx = np.array(x, dtype=\"float\") / 255.0\n\n\nprediction=model5.predict(x)\nindex=np.argmax(prediction[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(classes_name[index], 100 * np.max(prediction[0]))\n)\n\n# %% [markdown]\n# We can see that model 5 is recognizing and classifying all images very nicely.\n\n# %% [markdown]\n# # **Conclusion**\n\n# %% [markdown]\n# We finally conclude that Model with specification\n# \n# Conv2D0 -> Conv2D1 -> Batchnormalization0 -> Maxpool0 -> Dropout -> Cov2D2 -> Conv2D3 -> batchnormalization -> Maxpool1 -> Dropout -> Conv2D4 -> Conv2D5 -> Conv2D6 -> Batchnormalization -> Maxpool2 -> Dropout -> FC0 -> Dropout -> FC1 -> Dropout -> Softmax with RMSprop optimizer, 100 epoches and 32 batch-size is giving 72.98% accuracy on our test data. \n# We can further improve our accuracy with more regularizations.","metadata":{"_uuid":"6dfe763c-9419-4e9d-be33-ddebbeb5dc2b","_cell_guid":"62813e77-ca2d-4523-ba3c-4281b252a1a4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}